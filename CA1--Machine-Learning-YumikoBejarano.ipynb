{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "749a6b13-9db2-468d-a8ea-3566e088a062",
   "metadata": {},
   "source": [
    "# <center> CCT College Dublin </center>\n",
    "\n",
    "## <center> Assessment Cover Page</center>\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "---\n",
    "\n",
    "<span style=\"font-size:larger;\">\n",
    "\n",
    "**Module Title:**&nbsp;&nbsp;&nbsp;Data Preparation\n",
    "\t\n",
    "**Assessment Title:**&nbsp;&nbsp;&nbsp;Machine Learning (10 ETCS)\n",
    "\t\n",
    "**Lecturer Name:**&nbsp;&nbsp;&nbsp;Dr. Muhammad Iqbal\n",
    "\t\n",
    "**Student Full Name:**&nbsp;&nbsp;&nbsp;Yumiko Maria Bejarano Azogue \n",
    "\t\n",
    "**Student Number:**&nbsp;&nbsp;&nbsp;2024144\n",
    "\t\n",
    "**Assessment Due Date:**&nbsp;&nbsp;&nbsp;21st April 2024\n",
    "\t\n",
    "**Date of Submission:**&nbsp;&nbsp;&nbsp;21st April 2024\n",
    "    \n",
    "</span> \n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "#### Declaration \n",
    "\n",
    "```\n",
    "By submitting this assessment, I confirm that I have read the CCT policy on Academic Misconduct and understand the implications of submitting work that is not my own or does not appropriately reference material taken from a third party or other source. I declare it to be my own work and that all material from third parties has been appropriately referenced. I further confirm that this work has not previously been submitted for assessment by myself or someone else in CCT College Dublin or any other higher education institution.\n",
    "```\n",
    "<br><br><br>\n",
    "\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02996e5-ddf6-425e-88e1-b524ca32639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score, auc, roc_curve, f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15f08ef-5b55-4220-aaa6-3f32d873333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import thi slibrary to suppress the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')   # The object 'warnings' is used to call the method 'filterwarnings' and ignore the warnings\n",
    "\n",
    "#sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f0d1c9-0e6c-4b88-9df2-ee5a338a3fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data file\n",
    "data = pd.read_csv('collegePlace.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3dc1f0-1c81-4c53-8f5f-23a76a86f35b",
   "metadata": {},
   "source": [
    "# The dataset has the following columns:\n",
    "\n",
    "* Age : Age At The Time Of Final Year\n",
    "* Gender : Gender Of Candidate\n",
    "* Stream : Engineering Stream That The Candidate Belongs To\n",
    "* Internships : Number Of Internships Undertaken During The Course Of Studies, Not Necessarily Related To College Studies Or Stream\n",
    "* CGPA : CGPA Till 6th Semester\n",
    "* Hostel : Whether Student Lives In College Accomodation\n",
    "* HistoryOfBacklogs : Whether Student Ever Had Any Backlogs In Any Subjects\n",
    "* PlacedOrNot : Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd19d7f-1fdb-4a10-b36f-12241f13f603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 records of the dataset\n",
    "print(\"First 5 records of the dataset:\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51744cd-bbf0-4e5c-a0e0-11a3561fa51d",
   "metadata": {},
   "source": [
    "# Meta information of Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876b6e42-d4eb-4a05-893f-6ac9fc7972f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about the dataframe\n",
    "print(\"\\nInformation about the dataframe:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130c61b9-3c20-42cd-bd39-5d865aa84796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics of the dataframe\n",
    "print(\"\\n Descriptive statistics of the dataframe:\")\n",
    "\n",
    "# Generate descriptive statistics for the DataFrame and transpose it for readability\n",
    "descriptive_stats = data.describe().T\n",
    "#print(descriptive_stats)\n",
    "\n",
    "# Apply a bar chart style to the 'mean' column\n",
    "styled_stats = descriptive_stats.style.bar(subset=['mean'], color='#205ff2')\n",
    "\n",
    "# Apply a background gradient based on standard deviation\n",
    "styled_stats = styled_stats.background_gradient(subset=['std'], cmap='Reds')\n",
    "\n",
    "# Apply a background gradient based on the 50th percentile\n",
    "styled_stats = styled_stats.background_gradient(subset=['50%'], cmap='coolwarm')\n",
    "\n",
    "# Display the styled statistics\n",
    "styled_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f988a8bd-1c8f-4962-80b6-a6ca1ead40f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics of the dataframe\n",
    "print(\"\\nDescriptive statistics of the dataframe:\")\n",
    "print(data.describe().loc[['mean', 'min', 'max']].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee95c38d-dbe5-4b4d-a79d-b860a54d0b74",
   "metadata": {},
   "source": [
    "### Descriptive Statistics Summary:\r\n",
    "\r\n",
    "- Age ranges from 19 to 30 years old.\r\n",
    "- The lowest number of internships recorded is 0 (no internships), while the highest is 3.\r\n",
    "- Most students did not reside in a hostel (average hostel occupancy is below 0.5).\r\n",
    "- Most students have no backlogs (average backlog count is below 0.5).\r\n",
    "- The majority of students have been successfully placed in jobs (placement rate is above 0.5).\r\n",
    "0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828a4366-bed6-452a-911f-f6eeee0dcbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renamed Columns\n",
    "data.rename(columns={'HistoryOfBacklogs': 'backlogs', 'PlacedOrNot': 'placed'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738d6b7c-ac54-4ad2-93af-5eef335f1a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Custom functions definitionabs\n",
    "# def get_scores(y, y_pred):\n",
    "#     data={'Accuracy': np.round(accuracy_score(y, y_pred),2),\n",
    "#     'Precision':np.round(precision_score(y, y_pred),2),\n",
    "#     'Recall':np.round(recall_score(y, y_pred),2),\n",
    "#     'F1':np.round(f1_score(y, y_pred),2),\n",
    "#     'ROC AUC':np.round(roc_auc_score(y, y_pred),2)}\n",
    "#     scores_df = pd.Series(data).to_frame('scores')\n",
    "#     return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0e05b6-655d-4e3d-98fa-942fa4aa8712",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  transformed into lowercase\n",
    "data = data.rename(columns=str.lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcedd048-17d3-4071-a6df-afc4c1115e8e",
   "metadata": {},
   "source": [
    "###  Checking for NaN values\n",
    "\n",
    "Fortunately data has no missing value\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcd0a8b-4deb-4390-a134-857f0ae4b060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if our dataset contains any NULL values\n",
    "print(\"\\nChecking for missing values:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a764dc41-776b-4601-aead-079b88f9630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting the duplicates\n",
    "# data.duplicated().sum() #1829"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33093970-8431-47bd-abb8-9e4793a23ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.drop_duplicates(inplace=True)\n",
    "# data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6165a8f-375b-4ab6-bc0d-17b33db7077c",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA) and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f3de66-a9dc-4d3f-8997-97fcaa20aba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define palette with colors for placed and not placed\n",
    "palette =['#d74a49', '#92ba92'] # (yes,no)\n",
    "#92ba92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a66f3f-2dea-41ce-ba8e-744604811be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = data.select_dtypes(include=['number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8635680-233a-48c4-8fe7-01240cef000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of numerical variables............\n",
    "numerical_features = data.select_dtypes(include=['number'])\n",
    "\n",
    "print('Number of numerical variables: ', len(numerical_features))\n",
    "print('\\n')\n",
    "\n",
    "print('Numeric Column names:', numerical_features.columns)\n",
    "print('\\n')\n",
    "\n",
    "# visualise the numerical variables........\n",
    "data[numerical_features.columns].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3ec4bf-47e0-4bb3-bca4-23cc7d592732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates Skewness measures the asymmetry of a distribution\n",
    "skewness = numeric_df.skew()\n",
    "skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273b6f65-d98f-4e92-b633-b64761498fc7",
   "metadata": {},
   "source": [
    "### Age Distribution by Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709be4f1-15fc-4910-a62f-0a643892194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame to count the occurrences of each unique 'age' value in the entire dataset\n",
    "age_counts_df = pd.DataFrame(data['age'].value_counts()).reset_index()\n",
    "\n",
    "# Renaming the columns of the DataFrame\n",
    "age_counts_df.columns = ['Unique Age Values', 'Counts']\n",
    "\n",
    "# Displaying the DataFrame showing the count of unique 'age' values in the entire dataset\n",
    "print(age_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d451eb6f-670f-4d25-b973-68f37a5a6e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the data by 'gender' and counting the occurrences of each unique 'age' value within each group\n",
    "age_counts_by_gender = data.groupby('gender')['age'].value_counts().reset_index(name='Counts')\n",
    "\n",
    "# Displaying the DataFrame showing the count of unique 'age' values for each gender\n",
    "print(age_counts_by_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a778ac93-653d-4018-8860-4edb5d93a7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plotting the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plotting age distribution for males (Lightblue)\n",
    "sns.barplot(x='age', y='Counts', data=age_counts_by_gender[age_counts_by_gender['gender'] == 'Male'], color='#a2d2ff', label='Male')\n",
    "\n",
    "# Plotting age distribution for females (Magenta)\n",
    "sns.barplot(x='age', y='Counts', data=age_counts_by_gender[age_counts_by_gender['gender'] == 'Female'], color='#faaac7', label='Female')\n",
    "\n",
    "# Adding total count in each bar\n",
    "for p in plt.gca().patches:\n",
    "    plt.gca().annotate(f\"{int(p.get_height())}\", (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', xytext=(0, 10), textcoords='offset points')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Age Distribution by Gender')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c42378-810a-4892-870d-fd288b448a27",
   "metadata": {},
   "source": [
    "## Placement Details by Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89dc305-f8b1-4db3-93fb-9a023eeb5a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placement Details by Gender\n",
    "# Data extraction\n",
    "male = data[data['gender'] == \"Male\"]\n",
    "female = data[data['gender'] == \"Female\"]\n",
    "total_male = male.shape[0]\n",
    "total_female = female.shape[0]\n",
    "total_male_pass = male[male['placed'] == 1].shape[0]\n",
    "total_female_pass = female[female['placed'] == 1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fdd9a7-4d8a-4204-96c3-397ea53a8c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of pass percentages\n",
    "pass_male_percentage = np.round((total_male_pass * 100) / total_male, 2)\n",
    "pass_female_percentage = np.round((total_female_pass * 100) / total_female, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b9ddd5-2455-4495-8e3d-0adef9f65c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details dictionary\n",
    "details = {\"Total Male\": [total_male],\n",
    "           \"Total Female\": [total_female],\n",
    "           \"Total male pass\": [total_male_pass],\n",
    "           \"Total female pass\": [total_female_pass],\n",
    "           \"% of Passed Male\": [pass_male_percentage],\n",
    "           \"% of Passed Female\": [pass_female_percentage]}\n",
    "\n",
    "details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fd2830-cbeb-4d7b-bf3b-1cfc1187ca8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the details in a bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Data for plotting\n",
    "categories = list(details.keys())\n",
    "values = list(details.values())  # Convert dict_values object to a list\n",
    "values = [item for sublist in values for item in sublist]  # Flatten the list\n",
    "colors = ['#a2d2ff', '#faaac7']\n",
    "\n",
    "# Plotting the data\n",
    "bars = ax.bar(categories, values, color=colors, alpha=0.7)\n",
    "\n",
    "# Adding text on each bar\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate('{}'.format(height),\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3),  # 3 points vertical offset\n",
    "                textcoords=\"offset points\",\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_title('Placement Details by Gender')\n",
    "\n",
    "# Custom legend with both male and female labels\n",
    "female_patch = plt.Line2D([0], [0], marker='o', color='w', label='Female', markerfacecolor='#faaac7', markersize=10)\n",
    "male_patch = plt.Line2D([0], [0], marker='o', color='w', label='Male', markerfacecolor='#a2d2ff', markersize=10)\n",
    "\n",
    "ax.legend(handles=[male_patch, female_patch])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d7b3be-77ca-45b6-a0a6-633093bab6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d268baa-0890-47f4-8bd2-50713d20ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-numeric columns before calculating correlation\n",
    "numeric_data = data.select_dtypes(include=[np.number])\n",
    "correlation_matrix = numeric_data.corr()\n",
    "\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5227e3-d26b-40f5-a84e-31dedc262e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correlation matrix heatmap\n",
    "sns.heatmap(correlation_matrix, cmap='RdBu', annot=True, vmin=-1, vmax=1)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dad98c7-4e47-443b-9194-68f4f4831b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_plot(df, col, title, palette):\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(5.2, 5), gridspec_kw={\"height_ratios\": (.1, .9)})\n",
    "    ax[0].set_title(title, fontsize=18)\n",
    "    sns.boxplot(y=pd.to_numeric(df['placed']), x=col, data=df, orient='h', ax=ax[0], palette=palette)\n",
    "    ax[0].set(yticks=[])\n",
    "    ax[0].set_ylabel('')\n",
    "    ax[0].set_xlabel('')\n",
    "    sns.countplot(x=col, data=df, ax=ax[1], hue=pd.to_numeric(df['placed']), palette=palette)\n",
    "    ax[1].set_xlabel(col, fontsize=16)\n",
    "    ax[1].set_yticks([])\n",
    "    for container in ax[1].containers:\n",
    "        ax[1].bar_label(container, fmt='%.1f')\n",
    "    plt.legend(title='Placed?', title_fontsize=14, labels=['no', 'yes'], fontsize=13, fancybox=True, shadow=True, frameon=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4393862e-3531-4c4e-ae02-deff8676626b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CGPA affect job placement.\n",
    "num_plot(data, 'cgpa', 'CGPA by Placed',palette)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186be88d-f0ad-4c71-8f69-cb7d96c43285",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[(data['cgpa'] == 5) & (data['placed'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89379951-b12a-4a07-a2bc-9867de37d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = data.loc[((data['age'] == 23) | (data['age'] == 24)) & (data['gender'] == 'Male') &\n",
    " ((data['stream'] == 'Information Technology') | (data['stream'] == 'Computer Science')) & (data['placed'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70766e27-c08c-4564-a4eb-e0b114b76cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(12,3))\n",
    "sns.boxplot(ax=ax[0], x='cgpa', data=df_1)\n",
    "sns.histplot(ax=ax[1], x='cgpa', data=df_1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e14b7e-700d-4279-a0e1-e0ddd5117cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed outliers\n",
    "df_clean = data.drop(list(data.loc[(data['cgpa'] == 5) & (data['placed'] == 1)].index))\n",
    "\n",
    "print('Removed {} outliers !'.format(len(data)-len(df_clean)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a3088e-3f96-4d7d-a3f6-70ca3cd8e80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots cleaned dataset\n",
    "num_plot(df_clean, 'cgpa', 'CGPA by Placed', palette)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07760289-9116-450a-8cda-957385a1199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fa1d39-29a1-497b-8e59-bbd2600f33a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9595cd53-e87f-433d-b0b1-84ee1444091e",
   "metadata": {},
   "source": [
    "# Encoding\r",
    "Since there is no order/hierarchy among the categorical features, they will be encoded by *One hot encoding* (using pd.get_dummies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da9b300-cf1b-43bc-a656-f01ff26b811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df_clean, drop_first=True)\n",
    "\n",
    "df_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fa73ca-6f3f-4224-9766-2578d1797bb5",
   "metadata": {},
   "source": [
    "## Splitting the data into training, testing, and validation sets   \n",
    "\n",
    "The last step in data preprocessing is to split the data into training, testing, and validation sets:\n",
    "* Training set: The neural network will be trained on this subset of the data.\n",
    "* Validation set: This set of data allows us to perform hyperparameter tuning (that is, tuning the number of hidden layers) using an unbiased source of data.\n",
    "* Testing set: The final evaluation of the neural network will be based on this subset of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2538840-5dd4-45be-9502-59dce07c5bdc",
   "metadata": {},
   "source": [
    "# First, let's separate the dataset into X (input features) and y (target variable):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a837416a-1e4f-473d-9a0c-edee0fee0f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into x(independent variables) and y(dependent variables)\n",
    "X = df_encoded.drop('placed', axis=1)\n",
    "\n",
    "y = df_encoded['placed']\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0898e4-e4bd-4d61-8daa-8aefe7a017e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0085159f-626b-4e4d-a4ad-144370023d14",
   "metadata": {},
   "source": [
    "#### Then, make the first split to split the data into the training set (80%) and the testing set (20%) according to the preceding diagram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fb20c1-69ed-483b-b723-022487c36e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into training and testing set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4feb492-2866-4214-95c9-7751eebab0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling \n",
    "# Only on Independent Variable to convert them into values ranging from -1 to +1\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test  = sc.fit_transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_train.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1efcebd-7bab-45d3-be5b-b7a1dcdf1b3e",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32163adb-b1b1-4c18-9c3f-2dc6e1eae04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing a random seed ensures reproducible results\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(9)\n",
    "np.random.seed(1)\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7fd406-62e0-48f4-a112-e0f11805840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b297c2-4f5c-4a9c-8bf2-f9219f9985a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add the first hidden layer:\n",
    "from keras.layers import Dense\n",
    "\n",
    "colum = X_train.shape[1]\n",
    "\n",
    "# Add the first hidden layer\n",
    "model.add(Dense(32, activation = 'relu', input_dim = colum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97ca587-c89b-4020-9071-b527565e5312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the second hidden layer\n",
    "model.add(Dense(16, activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d876a394-1cb9-4978-9db5-9e7cfc048d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we add the output layer as follows:\n",
    "# Add the output layer\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed99ce0-b283-4d25-a6a2-c09ad5f2ccf7",
   "metadata": {},
   "source": [
    "# Model compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e2f908-82c2-4549-888a-ac6df0e46b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we can run the compile() function as follows:\n",
    "    # Compile the model\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba15499-f1b5-418c-9584-53f4c6c0fe19",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb2224d-e10d-4b25-a58c-627744eca83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ebfb57-47eb-4f8e-85a1-59c850d40522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To train our MLP model defined in earlier steps, let's call the fit function. Let's train our model for 200 iterations:\n",
    "# Train the model for 200 epochs\n",
    "model.fit(X_train, y_train, epochs = 10) # 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8982ad06-b35f-44ca-9cee-a56474c599e0",
   "metadata": {},
   "source": [
    "# Results analysis\r\n",
    "Having successfully trained our MLP, let's evaluate our model based on the testing accuracy, confusion matrix, and receiver operating characteristic (ROC) curve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af709eb-326e-431b-a08f-6589a2ebf5f5",
   "metadata": {},
   "source": [
    "# Testing accuracy\n",
    "We can evaluate our model on the training set and testing set using the evaluate() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7222e2-1545-4a78-af9d-d3c154b89b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(X_train, y_train)\n",
    "print(\"Training Accuracy: %.2f%%\\n\" % (scores[1]*100))\n",
    "\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"Testing Accuracy: %.2f%%\\n\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bc83f1-ab82-43fa-86cc-6faa188fc2d1",
   "metadata": {},
   "source": [
    "# Confusion matrix\n",
    "\n",
    "The confusion matrix is a useful visualization tool that provides analysis on the true negative, false positive, false negative, and true positives made by our model. Beyond a simple accuracy metric, we should also look at the confusion matrix to understand the performance of the model.The definition of true negative, false positive, false negative, and true positives are as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e13d32-5eed-4aac-a020-2a65c3cbb9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred = y_test_pred.flatten()\n",
    "y_test_pred_new = np.where(y_test_pred.round(2) > 0.5, 1, 0)\n",
    "c_matrix = confusion_matrix(y_test, y_test_pred_new)\n",
    "c_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3b1752-1ae2-4a99-b61a-96d1f5993a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(c_matrix, annot=True,\n",
    "                 xticklabels=['No', 'Yes'],\n",
    "                 yticklabels=['No', 'Yes'],\n",
    "                 cbar=False, cmap='Blues')\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Test\")\n",
    "ax.set_title(\"Placed ?\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f2fe98-67da-4b6f-81fb-e86dc7410216",
   "metadata": {},
   "source": [
    "# ROC curve\n",
    "A receiver operating characteristic curve (ROC) is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied.\n",
    "\n",
    "For classification tasks, we should also look at the ROC curve to evaluate our model. The ROC curve is a plot with the True Positive Rate (TPR) on the y axis and the False Positive Rate (FPR) on the x axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e83a7af-9059-47ff-92f9-2cdc3525132c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "y_test_pred_probs = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426c93f8-f980-490c-84bb-5b8bf16cc360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Then, run the roc_curve function in order to get the corresponding false positive rate and true positive rate for the ROC curve:\n",
    "FPR, TPR, _ = roc_curve(y_test, y_test_pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ffdae1-d5a3-4703-a422-4a89089b0a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(FPR, TPR)\n",
    "plt.plot([0,1],[0,1],'--', color='black') #diagonal line\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e99679-f551-4f89-a7bb-cfc141334a85",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "From the preceding ROC Curve, we can see that the model performs rather well, close to the model ROC Curve shown in the preceding diagram. This shows that our model is able to differentiate samples of different classes, making good predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c01798-a1eb-4797-bfaf-3fa21a5fd5c9",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5d5014-a2e8-4f18-90fb-c4df76599ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "model = DecisionTreeClassifier() \n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Training Accuracy :\", model.score(X_train, y_train))\n",
    "print(\"Testing Accuaracy :\", model.score(X_test, y_test))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4710ec8e-3e67-4ad5-8afe-c9c4f62c5890",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7d56d7-dd68-45ca-89c4-c20c5ec5b4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Training Accuracy :\", model.score(X_train, y_train))\n",
    "print(\"Testing Accuracy :\", model.score(X_test, y_test))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae341d37-7b2c-4156-9528-b91f76e155c7",
   "metadata": {},
   "source": [
    "## k fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ae4f9b-7da8-4173-bf94-e246cb365fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k fold cross validatio\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cvs = cross_val_score(estimator = model, X = X_train, y = y_train, cv = 10)\n",
    "print(cvs, \"\\n Mean Accuracy :\", cvs.mean(), \"\\nStandard Deviation :\", cvs.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91611e1f-cd21-456a-8e70-88ce53eef200",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17591556-4c4d-4ad3-8dc4-452368b16448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Training Accuracy :\", model.score(X_train, y_train))\n",
    "print(\"Testing Accuracy :\", model.score(X_test, y_test))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116e44c0-dbb1-4360-a75d-48e403377e1f",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c50782d-ad8d-4e3c-b99d-5a2bd390a7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Training Accuracy :\", model.score(X_train, y_train))\n",
    "print(\"Testing Accuracy :\", model.score(X_test, y_test))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7234c8cf-bd6a-426c-a59d-a7bf96ed54c9",
   "metadata": {},
   "source": [
    "## k fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213b127c-c639-4e88-bc2a-54c6aa575080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k fold cross validatio\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cvs = cross_val_score(estimator = model, X = X_train, y = y_train, cv = 10)\n",
    "print(cvs, \"\\n Mean Accuracy :\", cvs.mean(), \"\\n Standard Deviation :\", cvs.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cce21a-8e54-4e24-8283-4761fd41ffa7",
   "metadata": {},
   "source": [
    "# Reference:\n",
    "Neural Network Projects with Python by James Loy Published by Packt Publishing, 2019\n",
    "https://www.analyticsvidhya.com/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
